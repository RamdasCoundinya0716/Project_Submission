# 👋 Hi, I'm Ramdas Coudinya!

## 🌟 About Me  
🔭 I’m currently working as a **Cloud Data Engineer** at **Tredence Inc.**, focusing on building **scalable data pipelines** and **automating cloud infrastructure**.  
🌱 I’m passionate about **DevOps practices** and currently exploring **container orchestration with Kubernetes** and **GitOps workflows using ArgoCD**.  
👯 I’m looking to collaborate on projects involving **real-time data pipelines**, **infrastructure automation**, and **DevOps tooling**.  
💬 Ask me about **SQL, PySpark, ETL pipelines, cloud infrastructure**, and **CI/CD automation**.  
📫 How to reach me: **ramdasvk4@gmail.com**  
😄 Pronouns: **He/Him**  
⚡ Fun fact: I once **reduced deployment time by 67%** by automating infrastructure using **Terraform** and **Jenkins**!

---

## 🚀 My Projects  
Here are some of the exciting projects I've worked on. Check them out and feel free to star them if you like what you see!

### 📐 [Three-Tier Web Application Deployment on AWS EKS](https://github.com/RamdasCoundinya0716/three-tier-devsecops-project.git)  
**Technologies Used:** AWS EKS, ArgoCD, Jenkins, Terraform, Prometheus, Grafana, Helm  
**Description:** Deployed a **scalable three-tier web application** (ReactJS, NodeJS, MongoDB) on **AWS EKS**. Automated the CI/CD process using **Jenkins** and **ArgoCD** with GitOps practices. Implemented **monitoring and observability** using **Prometheus** and **Grafana** and provisioned infrastructure with **Terraform**.

---

### 📊 [Scalable Cloud-Based Data Pipeline for YouTube Analytics](https://github.com/RamdasCoundinya0716/)  
**Technologies Used:** AWS S3, Glue, Lambda, QuickSight  
**Description:** Developed a **scalable cloud-based data pipeline** to ingest, transform, and store YouTube data for real-time analysis. Enabled insights into trending video metrics across different regions.

---

### 🌐 [Stock Market Kafka Real-Time Data Engineering Project](https://github.com/RamdasCoundinya0716/)  
**Technologies Used:** Apache Kafka, AWS S3, Glue, Athena, EC2  
**Description:** Built an **end-to-end real-time data pipeline** for ingesting and processing **live stock market data**. The solution enables **real-time data analysis** and secure storage, with **EC2** used for Kafka management and **Python** for scripting.

---

## 💻 Skills  
### Data Engineering  
- **Programming Languages:** Python, SQL, Bash  
- **Data Tools:** Spark, Kafka, PySpark, Airflow, Databricks  
- **Cloud Platforms:** AWS, GCP  
- **Data Storage:** S3, ADLS, GCS, HDFS  

### DevOps  
- **CI/CD Tools:** Jenkins, GitHub Actions  
- **Infrastructure as Code:** Terraform, Helm  
- **Containerization:** Docker, Kubernetes  
- **Monitoring & Observability:** Prometheus, Grafana  
- **Version Control:** Git  

---

## 🚀 DevOps Enthusiast  
I’m a **DevOps enthusiast**, passionate about **infrastructure automation**, **CI/CD pipelines**, and **GitOps practices**. I love exploring tools like **Terraform**, **Jenkins**, **ArgoCD**, and **Helm** to streamline the deployment process and ensure **reliable and scalable infrastructure**.

---

### 📚 My Articles  
Coming Soon! Stay tuned for blogs on **DevOps practices**, **real-time data engineering**, and **cloud automation tips**.

## 🏆 Achievements
- Improved data processing efficiency by 25% at my current role.
- Automated infrastructure provisioning, reducing deployment time significantly.

## 🤝 Connect with Me
- [LinkedIn](https://www.linkedin.com/in/ramdascoudinya)
- [GitHub](https://github.com/RamdasCoundinya0716)
